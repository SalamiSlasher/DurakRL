# Reinforcement Learning for Strategic Decision-Making in the Card Game Durak

## 1. Project Title
**Reinforcement Learning for Strategic Decision-Making in the Card Game Durak**

## 2. Team Members
- Danil    Gudebskiy  22B031613
- Sanzhar  Akhmedov   21B031329


## 3. Introduction
Durak is multiplayer game with strategic decision-experience & unknown state. We think it's good learning experience making a model for this game

## 4. Problem Statement
The problem we aim to address is how an RL agent can learn to make optimal decisions in an environment with partial observability and multiple players, where the outcome of each action is uncertain. This problem is significant because it explores the application of RL in complex, multi-agent environments, which has broader implications for strategic decision-making in uncertain scenarios.

## 5. Objectives
- Develop an RL agent that can learn and execute effective strategies in the game of Durak
- Investigate different RL algorithms (for instance Deep Q-Networks) and their suitability for the game
- Evaluate the performance of the RL agent against human players and/or rule-based agents
- Identify and analyze the key factors that influence the agent's decision-making process in the context of Durak
- * Possibly develop a GYM environment

## 6. Methodology
We will begin by defining the game's environment and reward structure, where the agent receives positive rewards for winning and negative rewards for unfavorable outcomes. The RL algorithms we plan to explore include Q-learning for tabular cases and Deep Q-Networks (DQN) for more complex scenarios. We will implement these algorithms using Python, leveraging libraries such as PyTorch for neural network models and OpenAI's Gym for environment simulation. Testing will be conducted by pitting the RL agent against various opponents, including baseline rule-based agents and potentially human players.

## 7. Personal Contribution
*Haven't done any yet

## 8. Feasibility Analysis
Our initail goal is to make an agent that is suitable for one on one play. If no roadblock were to happen we plan to make it with variable player count, and different rule sets.

## 9. Timeline and Milestones
- **Week 1-6:** Learning basics & find (or build) environment for our agent training
- **Week 6-11:** Experiment with policies & develop proof of concept
- **Week 11-15:** Testing & improving 

## 10. References
- PAK. Alexander
